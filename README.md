# Lilly AI | Project VSM V2.5 Development Information Document Showing **Major** Updates And Patch Notes

[![Project Status: Active](https://img.shields.io/badge/Project%20Status-Active-brightgreen)](https://github.com/your-username/your-repo)
[![Version](https://img.shields.io/badge/Version-2.5-blue)](https://github.com/your-username/your-repo)

Lilly AI **(Lilly AI Self Named)** is a state-of-the-art virtual content creator developed for the **VSM** group by member Kill3rKai. Lilly V2.5 is designed to function as an autonomous AI VTuber capable of real-time audience interaction, personality-driven gaming, and dynamic live-stream content.

## ðŸŒŸ Overview
Lilly V2.5 represents a significant leap from previous iterations, focusing on reduced latency, more natural speech patterns, and a complex, stronger, filter system. Unlike standard chatbots, Lilly is optimized for the high-energy environment of live streaming.

## ðŸš€ Key Features
- **Personality Engine:** A custom Large Language Model (LLM) fine-tuned for the unique "Lilly" personaâ€”balancing wit, curiosity, and VSM group inside jokes.
- **Dynamic Content Filter:** A multi-layered safety system that blocks prohibited content while generating character-appropriate "annoyed" or "sassy" responses when boundaries are hit.
- **Low-Latency TTS:** High-fidelity voice synthesis designed for real-time conversation.
- **Vision & Perception:** Ability to perceive stream events and react to visual stimuli, In order to play games and interact.
- **Avatar:** To Humanize It.
- **Browser:** It can Google search if it is unsure
- **Discord:** It can, Chat, DM, Talk in Voice Calls

## ðŸ›  Tech Stack
* **Language:** Python 3.10+
* **Core AI:** Custom LLM With Mistral & Llama 3
* **Voice:** W.I.P
* **Integration:** Discord currently
* **Avatar:** W.I.P

## ðŸ§  System Overview

The system is designed with a clear separation of concerns, allowing intelligence, memory, safety, and communication to operate independently while remaining tightly coordinated.

At its core, the system orchestrates user interactions by analyzing intent, maintaining context, and generating responses that align with defined behavioral traits. A central controller manages the overall logic flow, ensuring that inputs pass through moderation, intent classification, memory retrieval, and response generation in a consistent and reliable order.

Conversation handling includes both short-term working context and long-term historical recall, enabling continuity across interactions while preserving session state. Persistent data is used to retain important information beyond a single run, while active session data tracks the current conversational flow.

Response generation is handled through a dedicated inference layer, which constructs candidate replies and evaluates them for quality, relevance, and safety before selecting a final output. Additional scoring and filtering logic ensures responses remain coherent, appropriate, and aligned with system guidelines.

Personality and behavior are governed by a configurable persona layer, allowing the system to consistently apply character traits, tone, and style across all interactions.

External communication layers allow the intelligence core to be accessed through multiple interfaces, such as terminal-based interaction or real-time messaging platforms, without coupling those interfaces to the internal logic.

Finally, shared utilities and configuration assets support the system by providing reusable helper logic, static data, and environment definitions required for stable operation.
